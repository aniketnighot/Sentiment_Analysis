{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": " **Sentiment Analysis with Keras and TensorFlow**.\n\n## Task : The IMDB Reviews Dataset\n_",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from tensorflow.keras.datasets import imdb\n\n(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = 10000)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "print(x_train[0])",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "print(y_train[0])",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "class_names = ['Negative', 'Positive']",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "word_index = imdb.get_word_index()\nprint(word_index['hello'])",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Task : Decoding the Reviews\n\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "reverse_word_index = dict((value, key) for key, value in word_index.items())\n\ndef decode(review):\n    text = ''\n    for i in review:\n        text += reverse_word_index[i]\n        text += ' '\n    return text",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "decode(x_train[0])",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def show_lengths():\n    print('Length of 1st training example: ', len(x_train[0]))\n    print('Length of 2nd training example: ',  len(x_train[1]))\n    print('Length of 1st test example: ', len(x_test[0]))\n    print('Length of 2nd test example: ',  len(x_test[1]))\n    \nshow_lengths()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "\n## Task : Padding the Examples\n\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "word_index['the']",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from tensorflow.keras.preprocessing.sequence import pad_sequences\n\nx_train = pad_sequences(x_train, value = word_index['the'], padding = 'post', maxlen = 256)\nx_test = pad_sequences(x_test, value = word_index['the'], padding = 'post', maxlen = 256)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "show_lengths()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "decode(x_train[0])",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Task : Word Embeddings and Creating and Training the Model\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, Dense, GlobalAveragePooling1D\n\nmodel = Sequential([\n    Embedding(10000, 16),\n    GlobalAveragePooling1D(),\n    Dense(16, activation = 'relu'),\n    Dense(1, activation = 'sigmoid')\n])\n\nmodel.compile(\n    optimizer = 'adam',\n    loss = 'binary_crossentropy',\n    metrics = ['acc']\n)\n\nmodel.summary()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from tensorflow.keras.callbacks import LambdaCallback\n\nsimple_logging = LambdaCallback(on_epoch_end = lambda e, l: print(e, end='.'))\n\nE = 5\n\nh = model.fit(\n    x_train, y_train,\n    validation_split = 0.2,\n    epochs = E,\n    callbacks = [simple_logging],\n    verbose = False\n)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": "## Task : Predictions and Evaluation\n\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "%matplotlib inline\n\nimport matplotlib.pyplot as plt\n\nplt.plot(range(E), h.history['acc'], label = 'Training')\nplt.plot(range(E), h.history['val_acc'], label = 'Validation')\nplt.legend()\nplt.show()",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "loss, acc = model.evaluate(x_test, y_test)\nprint('Test set accuracy: ', acc * 100)",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\n\nprediction = model.predict(np.expand_dims(x_test[0], axis = 0))\nclass_names = ['Negative', 'Positive']\nprint(class_names[int(np.squeeze(prediction[0]) > 0.5)])",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "print(decode(x_test[0]))",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}
